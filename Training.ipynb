{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTtd3dugnn/ROSCYsG5Cl8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peppievt/Gated-training/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Ia8AaPtDl-"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import specgram\n",
        "from matplotlib import style\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import keras\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "\n",
        "from keras.utils import np_utils, to_categorical\n",
        "import pickle\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.sparse as sparse\n",
        "import random\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8-cVRzDtGai"
      },
      "source": [
        "#adres = r'C:\\Users\\pepij\\Documents\\Uni\\Datascience\\Thesis\\baldey_audio\\real_compound'\n",
        "#in colab:\n",
        "adres = r'/content/gdrive/My Drive/Colab Notebooks/data/'\n",
        "learning_Rate = 0.002\n",
        "one_hot = True\n",
        "style.use('dark_background')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "#lengte = output dimensie\n",
        "lengte = 2260\n",
        "ones = 1\n",
        "df = None\n",
        "if df is not None:\n",
        "    del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nO3SYDSVW2H"
      },
      "source": [
        "def create_Y():\n",
        "    woordenlijst = []\n",
        "    for i in dir_list:\n",
        "        if i.endswith('.wav'):\n",
        "            woordenlijst.append(i[:-4])\n",
        "    return woordenlijst\n",
        "\n",
        "def create_RandomVector():\n",
        "    Vec = np.zeros(lengte)\n",
        "    randomlist = random.sample(range(0, lengte), ones)\n",
        "    for i in randomlist:\n",
        "        Vec[i] = 1\n",
        "    return np.asarray(Vec)\n",
        "\n",
        "def create_map_Vectors(woordenlijst):\n",
        "    omzet_df = pd.DataFrame(columns = ['woord', 'vector'])\n",
        "    woorden, vectoren, check_doubles = [],[],[]\n",
        "    c = 0\n",
        "    for i in set(woordenlijst):\n",
        "        woorden.append(i)\n",
        "        vecie = create_RandomVector()\n",
        "        while any((vecie == x).all() for x in vectoren):\n",
        "            vecie = create_RandomVector()\n",
        "        else:\n",
        "            vectoren.append(vecie)\n",
        "        c+=1\n",
        "    print(\"unique vectors: \",len(np.unique(vectoren, axis=0)))\n",
        "    omzet_df['woord'] = woorden\n",
        "    omzet_df['vector'] = vectoren\n",
        "    dictionary = dict(zip(omzet_df['woord'], omzet_df['vector']))\n",
        "    return dictionary\n",
        "\n",
        "def solve_table(df, di):\n",
        "    df['Y'] = df['name'].map(di)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-a3oV1stLOl",
        "outputId": "2a95f974-7c81-4eb6-fd82-e96801fddb11"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgr0rXkCthGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f55ca5-db1c-408b-d7fb-bd9b812f25ae"
      },
      "source": [
        "# for trainingset:\n",
        "df_features = pd.read_pickle(adres + 'Baldey_features/real_2_specto_baldey.pkl')\n",
        "df_names = pd.read_pickle(adres + 'Baldey_features/real_2_specto_baldey_names.pkl')\n",
        "\n",
        "df = pd.DataFrame(df_features['feature'].values.tolist(), columns=['feature'])\n",
        "df['name'] = df_names\n",
        "dictionary = create_map_Vectors(df['name']) \n",
        "\n",
        "df = solve_table(df, dictionary)\n",
        "\n",
        "df['Y']=df['Y']/ones\n",
        "\n",
        "print(\"trainingset generated\")\n",
        "\n",
        "#for validation sets:\n",
        "df_2 = pd.DataFrame(columns=['valX', 'val_name'])\n",
        "val_X = pd.read_pickle(adres + 'Baldey_features/fake_2_specto_baldey.pkl')\n",
        "val_name = pd.read_pickle(adres + 'Baldey_features/fake_2_specto_baldey_names.pkl')\n",
        "df_2 = pd.DataFrame(val_X['feature'].values.tolist(), columns=['valX'])\n",
        "df_2['val_name'] = val_name\n",
        "df_2['valY'] = df_2['val_name'].map(dictionary)\n",
        "df_2['valY']= df_2['valY']/ones\n",
        "\n",
        "print(\"training: \",len(df))\n",
        "print(\"validation: \", len(df_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "unique vectors:  2260\n",
            "trainingset generated\n",
            "training:  2260\n",
            "validation:  4520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pJjIYqtLgF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da343b8f-5f88-4f6e-e841-b1564fadfd50"
      },
      "source": [
        "#Create train/validation split:\n",
        "\n",
        "X_train = df['feature']\n",
        "y_train = df['Y']\n",
        "lennie = len(df_2['valX'])\n",
        "X_val = df_2['valX'][0:int(0.5*lennie)]\n",
        "y_val = df_2['valY'][0:int(0.5*lennie)]\n",
        "X_test = df_2['valX']\n",
        "y_test = df_2['valY']\n",
        "\n",
        "print(\"yval = \", y_val.shape)\n",
        "print(\"ytest = \",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yval =  (2260,)\n",
            "ytest =  (4520,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ddUqbZIXjgSJ",
        "outputId": "11f5d895-8784-4de9-c686-b9e51f62c18d"
      },
      "source": [
        "''' scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "for i in range(len(X_train)):\n",
        "    X_train[i] = np.array(scaler.fit_transform(X_train[i]))\n",
        "for i in range(len(X_val)):\n",
        "    X_val[i] = np.array(scaler.fit_transform(X_val[i]))\n",
        "for i in range(len(X_test)):\n",
        "    X_test[i] = np.array(scaler.fit_transform(X_test[i]))\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)\n",
        "print(\"validation size: \", len(X_val))\n",
        "print(\"test size: \", len(X_test))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' scaler = MinMaxScaler(feature_range=(-1, 1))\\nfor i in range(len(X_train)):\\n    X_train[i] = np.array(scaler.fit_transform(X_train[i]))\\nfor i in range(len(X_val)):\\n    X_val[i] = np.array(scaler.fit_transform(X_val[i]))\\nfor i in range(len(X_test)):\\n    X_test[i] = np.array(scaler.fit_transform(X_test[i]))\\ny_train = np.array(y_train)\\ny_val = np.array(y_val)\\ny_test = np.array(y_test)\\nprint(\"validation size: \", len(X_val))\\nprint(\"test size: \", len(X_test))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPJ1h8Oq9Gce",
        "outputId": "a38e95a6-c140-4a68-935c-e3a45fe61c37"
      },
      "source": [
        "#AANGEPAST VOOR SPINOFF-EXPERIMENT:\n",
        "# choose 200 options\n",
        "options = []\n",
        "for i in range(len(y_train)):\n",
        "    if i < 201:\n",
        "        options.append(np.argmax(y_train[i]))\n",
        "# generate same options for val and test\n",
        "argmax_opties = []\n",
        "for i in range(len(y_val)):\n",
        "       if np.argmax(y_val[i]) in options:\n",
        "           argmax_opties.append(i)\n",
        "print(len(argmax_opties))\n",
        "print(argmax_opties[0:50])\n",
        "# put correct samples in new sets:\n",
        "print(\"-------------------------\")\n",
        "print(\"training size: \", len(X_train))\n",
        "print(\"val size: \", len(X_val))\n",
        "print(\"test size: \", len(X_test))\n",
        "\n",
        "X_train = X_train[0:200]\n",
        "y_train = y_train[0:200]\n",
        "\n",
        "X_val = [X_val[i] for i in range(len(X_val)) if i in argmax_opties]\n",
        "y_val = [y_val[i] for i in range(len(y_val)) if i in argmax_opties]\n",
        "\n",
        "X_val = X_val[0:200]\n",
        "y_val = y_val[0:200]\n",
        "print(\"-------------------------\")\n",
        "print(\"training size: \", len(X_train))\n",
        "print(\"val size: \", len(X_val))\n",
        "print(\"test size: \", len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "382\n",
            "[1, 2, 4, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "-------------------------\n",
            "training size:  2260\n",
            "val size:  2260\n",
            "test size:  4520\n",
            "-------------------------\n",
            "training size:  200\n",
            "val size:  200\n",
            "test size:  4520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JpZkGh02jNZ",
        "outputId": "870609c6-4050-4f73-9599-d1aacc08f310"
      },
      "source": [
        "print(X_train[0].shape)\n",
        "print(np.argmax(y_train[0]))\n",
        "print(np.max(y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 68)\n",
            "823\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j8AaUkCuN1_"
      },
      "source": [
        "# unpack the x = [nr_of_samples,] array to: [nr_of_samples, length]\n",
        "def unpack_arrays(x):\n",
        "    data_x = []\n",
        "    for i in range(len(x)):\n",
        "        temp = [x[i]]\n",
        "        data_x.extend(temp)\n",
        "    return np.asarray(data_x)\n",
        "    \n",
        "#computes the cosine similarity between two vectors:    \n",
        "def cosine_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "\n",
        "#given a sample and the names/random vectors dictionary: calculate the cosine similarity for the entire list.\n",
        "def cosine_sim_list(a, b):\n",
        "    lijst = [cosine_sim(a,x) for x in b]\n",
        "    return lijst\n",
        "\n",
        "#full samples added: if gates = False, else; split in 1/nr_of_gates\n",
        "def create_gated_samples(X_train, y_train, nr_of_gates=2, gates = True):\n",
        "    ey = []\n",
        "    ex = pd.Series()\n",
        "    counter = 0\n",
        "    for x in X_train:\n",
        "        step_number = int(len(x[0]))\n",
        "        if gates == False:\n",
        "            step = step_number\n",
        "        else:\n",
        "            step = int(step_number/nr_of_gates)\n",
        "        x = x.T\n",
        "        for i in range(1,nr_of_gates,1):\n",
        "            ex= pd.Series([x[:step*i][:].T])\n",
        "            X_train[len(X_train)] = ex[0]\n",
        "            #ey aanpassen met Entropywaarde 5 -> [0/5, 0.5/sum(samples) voor alle andere samples)]\n",
        "            y = y_train[counter]*0.5\n",
        "            y = [0.5/len(y) if i< 0.4 else i for i in y]\n",
        "            ey.append(y)\n",
        "        counter +=1\n",
        "    y_train = unpack_arrays(y_train)\n",
        "    y_train = np.concatenate([y_train, ey])\n",
        "    return X_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO8tA46EUmkT",
        "outputId": "fb61182a-6a27-48d7-8e6c-5cd218f3bb2e"
      },
      "source": [
        "#Create augmented samples:\n",
        "print(\"length of X and Y before: \", len(X_train), len(y_train))\n",
        "#X_train, y_train = create_gated_samples(X_train, y_train, gates = False)\n",
        "print(\"length of X and Y after: \", len(X_train), len(y_train))\n",
        "#print(y_train[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of X and Y before:  200 200\n",
            "length of X and Y after:  200 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quZxg9sI4RU2",
        "outputId": "4d2df834-bfab-467e-c0d2-66477bf7989d"
      },
      "source": [
        "#check:\n",
        "print(X_train[0].shape)\n",
        "print(X_train[len(X_train)/2].shape)\n",
        "\n",
        "#perform transpose operations:\n",
        "\n",
        "print(\"shape before: \", X_train[0].shape)\n",
        "print(X_train[len(X_train)/2].shape)\n",
        "\n",
        "X_train = [x.T for x in X_train]\n",
        "X_val = [x.T for x in X_val]\n",
        "X_train = pd.Series(X_train)\n",
        "X_val = pd.Series(X_val)\n",
        "print(\"shape after: \", X_train[0].shape)\n",
        "print(X_train[len(X_train)/2].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 68)\n",
            "(128, 54)\n",
            "shape before:  (128, 68)\n",
            "(128, 54)\n",
            "shape after:  (68, 128)\n",
            "(54, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Vol5a3fUGO",
        "outputId": "f385c721-c19c-4bb9-c311-47586632804d"
      },
      "source": [
        "print(len(X_train[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLpbuQMnuT7g"
      },
      "source": [
        "#if one_hot is False:\n",
        "#    print(\"false\")\n",
        "#    y_train = unpack_arrays(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqQMvPWUuVel"
      },
      "source": [
        "def model_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(512, input_shape=(None,128)))\n",
        "    model.add(Dense(len(y_train[0])))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQQAcEAEubek"
      },
      "source": [
        "# functions for plotting the results.\n",
        "def plot_model(model_history):\n",
        "    if ones == 1:\n",
        "        metric = 'accuracy'\n",
        "    else:\n",
        "        metric = 'top_k_categorical_accuracy'\n",
        "    plt.plot(model_history.history['loss'], color='blue')\n",
        "    plt.plot(model_history.history['val_loss'], color ='red')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.plot(model_history.history[metric], color='blue')\n",
        "    plt.plot(model_history.history['val_'+ metric], color = 'red')\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train','validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def save_other_info():\n",
        "    np.save(\"X_train\", X_train)\n",
        "    np.save(\"X_val\", X_val)\n",
        "    np.save(\"X_test\", X_test)\n",
        "    np.save(\"y_train\", y_train)\n",
        "    np.save(\"y_val\", y_val)\n",
        "    np.save(\"y_test\", y_test)\n",
        "    with open('dict.p', 'wb') as fp:\n",
        "        pickle.dump(dictionary, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# Save model and weights\n",
        "def save_model(model_name, model):\n",
        "    print(model_name)\n",
        "    model_name = model_name\n",
        "    %cd /content/gdrive/My Drive/Colab Notebooks/data\n",
        "    save_dir = os.path.join('/content/gdrive/My Drive/Colab Notebooks/data', 'saved_models')\n",
        "    print(save_dir)\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    model_path = os.path.join(save_dir, model_name)\n",
        "    model.save(model_path)\n",
        "    np.save(model_path + \"/X_train\", X_train)\n",
        "    np.save(model_path + \"/X_val\", X_val)\n",
        "    np.save(model_path + \"/X_test\", X_test)\n",
        "    np.save(model_path + \"/y_train\", y_train)\n",
        "    np.save(model_path + \"/y_val\", y_val)\n",
        "    np.save(model_path + \"/y_test\", y_test)\n",
        "    \n",
        "    with open(model_path + '/dict.p', 'wb') as fp:\n",
        "        pickle.dump(dictionary, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('Save model and weights at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZB0NwvFu-4X"
      },
      "source": [
        "#batch generator class:\n",
        "from random import random\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras models'\n",
        "    def __init__(self, X_train, labels, batch_size=1, dim=(len(X_train),None,len(X_train[0][0])), shuffle=False, gated=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.X_train = X_train\n",
        "        self.on_epoch_end()\n",
        "        self.shuffle=shuffle\n",
        "        self.gated = gated\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.X_train) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        ki = self.indexes[index]\n",
        "        X = np.expand_dims(X_train[ki], axis=0)\n",
        "        yi = y_train[ki]\n",
        "        #alleen aanzetten voor minitest:\n",
        "        if self.gated:\n",
        "            rand = random()\n",
        "            if rand < 0.5 and rand > 0.05:\n",
        "                length = rand*2\n",
        "                X = X[:,0:int(length*len(X[0])) ,:]\n",
        "                yi = yi*length\n",
        "                yi = [length/len(yi) if i< length else i for i in yi]\n",
        "        y = np.expand_dims(yi, axis=0)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Twzzadl6Gc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219bf096-08f1-45fc-d90c-b5f798d72fd0"
      },
      "source": [
        "training_generator = DataGenerator(X_train, y_train, gated=True)\n",
        "validation_generator = DataGenerator(X_val, y_val)\n",
        "print(\"lengte trainingset: \",len(training_generator))\n",
        "print(\"lengte validatieset: \",len(validation_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lengte trainingset:  200\n",
            "lengte validatieset:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F_Tb63FueDu"
      },
      "source": [
        "def run(model, learning_Rate):\n",
        "    if ones == 1:\n",
        "        metric = 'accuracy'\n",
        "    else:\n",
        "        metric = accie\n",
        "    #Noam decay of learning rate\n",
        "    print(learning_Rate)\n",
        "    global_Step = 0\n",
        "    step = (global_Step + 1)\n",
        "    warmup_Steps = 400.0\n",
        "    learning_Rate *= warmup_Steps ** 0.5 * np.minimum(step * warmup_Steps**-1.5, step**-0.5)\n",
        "    #Adam optimizer\n",
        "    opt = keras.optimizers.Adam(lr=learning_Rate)\n",
        "    accie = tf.keras.metrics.TopKCategoricalAccuracy(k=ones, name=\"top_k_categorical_accuracy\", dtype=None)\n",
        "    #compile and build model:\n",
        "    model.compile(loss='cosine_similarity', optimizer=opt, metrics=metric)\n",
        "    model_history = model.fit(training_generator, steps_per_epoch=len(X_train), validation_data=validation_generator, epochs=600,  verbose=0)\n",
        "    plot_model(model_history) \n",
        "    print(learning_Rate)\n",
        "    return model, learning_Rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMXV32AHjB8G",
        "outputId": "c744a8e9-04e0-4c4b-cccf-41c6c0c613e7"
      },
      "source": [
        "model = model_LSTM()\n",
        "learning_Rate = 0.002\n",
        "x, learning_Rate = run(model, learning_Rate)\n",
        "save_model(\"(2500,1)_mini_test_3-3_gated_600\", x)\n",
        "epochs = 600"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, 512)               1312768   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2260)              1159380   \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 2260)              0         \n",
            "=================================================================\n",
            "Total params: 2,472,148\n",
            "Trainable params: 2,472,148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "0.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9i8UtN78Z6I"
      },
      "source": [
        "hist = model.history.history['accuracy']\n",
        "hist_loss = model.history.history['loss']\n",
        "print(\"accuracy: \",hist[-1])\n",
        "print(\"loss: \", hist_loss[-1])\n",
        "np.save(\"model_acc_\" + str(epochs), hist)\n",
        "np.save(\"model_loss_\"+ str(epochs), hist_loss)\n",
        "np.save(\"model_val_acc_\" + str(epochs), model.history.history[\"val_accuracy\"])\n",
        "np.save(\"model_val_loss_\"+ str(epochs), model.history.history[\"val_loss\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTRX_TGy_ccC",
        "outputId": "c5871f32-b4c4-4129-ee04-78d0bc92ff40"
      },
      "source": [
        "print(model.history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.029748626053333282, -0.03132721409201622, -0.031633708626031876, -0.03196489438414574, -0.03241903707385063, -0.03309467062354088, -0.03409312665462494, -0.0354282408952713, -0.037080615758895874, -0.03899482637643814, -0.04114321246743202, -0.043620314449071884, -0.046325474977493286, -0.049249403178691864, -0.052373871207237244, -0.05574239417910576, -0.05928408354520798, -0.06302028894424438, -0.06699711084365845, -0.07086554914712906, -0.0755590870976448, -0.07997600734233856, -0.08483091741800308, -0.0900847539305687, -0.09551087021827698, -0.10071557760238647, -0.10630272328853607, -0.11247047781944275, -0.11843384802341461, -0.12430411577224731, -0.13151104748249054, -0.13789421319961548, -0.14396128058433533, -0.15143325924873352, -0.15878303349018097, -0.1658685803413391, -0.1728535294532776, -0.18083050847053528, -0.18848837912082672, -0.19652985036373138, -0.2051280438899994, -0.21174652874469757, -0.22116711735725403, -0.22907541692256927, -0.23855939507484436, -0.2465582937002182, -0.25444212555885315, -0.264451265335083, -0.27349406480789185, -0.28170058131217957, -0.29145681858062744, -0.3001691699028015, -0.3103298246860504, -0.31924739480018616, -0.3292761445045471, -0.33779072761535645, -0.3474188446998596, -0.3584756553173065, -0.3667777180671692, -0.3783619999885559, -0.3859800100326538, -0.3969728946685791, -0.40541282296180725, -0.41492748260498047, -0.4254704415798187, -0.43459752202033997, -0.4453379511833191, -0.45626965165138245, -0.4628300070762634, -0.47352996468544006, -0.4842744767665863, -0.4952182471752167, -0.5039927959442139, -0.5153233408927917, -0.5205172896385193, -0.5349875092506409, -0.5446365475654602, -0.5516102313995361, -0.5610532760620117, -0.5727973580360413, -0.5797320604324341, -0.5905848145484924, -0.5984784960746765, -0.6083379983901978, -0.6180184483528137, -0.6256746649742126, -0.6350170969963074, -0.6424559950828552, -0.6533344388008118, -0.6603384613990784, -0.6679707765579224, -0.6777265071868896, -0.688134491443634, -0.6953951716423035, -0.7020379900932312, -0.7109383344650269, -0.7188361287117004, -0.7263096570968628, -0.7334200143814087, -0.7435325384140015, -0.7485284805297852, -0.7580510973930359, -0.7584965229034424, -0.7696348428726196, -0.7758691906929016, -0.7840183973312378, -0.7874558568000793, -0.7982256412506104, -0.7999763488769531, -0.809058666229248, -0.8155560493469238, -0.8227596879005432, -0.8267569541931152, -0.8320606350898743, -0.8351792693138123, -0.8451514840126038, -0.8482556939125061, -0.8542118072509766, -0.8578253984451294, -0.8639764785766602, -0.8688309192657471, -0.8757526278495789, -0.8756688237190247, -0.8768038749694824, -0.8864620327949524, -0.8883399367332458, -0.8962602019309998, -0.8996171355247498, -0.9000834226608276, -0.9038667678833008, -0.9088183641433716, -0.9154000878334045, -0.9152331948280334, -0.9214481711387634, -0.9226288199424744, -0.9230483770370483, -0.9256688952445984, -0.9301151633262634, -0.9320301413536072, -0.9382621049880981, -0.9375437498092651, -0.9353342652320862, -0.9468205571174622, -0.9440075159072876, -0.9484674334526062, -0.9499543309211731, -0.9480190277099609, -0.9554252028465271, -0.9522387385368347, -0.9558794498443604, -0.9617902636528015, -0.9592643976211548, -0.956550657749176, -0.9653062224388123, -0.9676427245140076, -0.9638968706130981, -0.9614450335502625, -0.9687410593032837, -0.9663484692573547, -0.9720180034637451, -0.9593497514724731, -0.9686697125434875, -0.9720368385314941, -0.9777052998542786, -0.9714670777320862, -0.9668630957603455, -0.9764627814292908, -0.9711971282958984, -0.97639000415802, -0.9761671423912048, -0.9826042056083679, -0.9661616683006287, -0.9743927717208862, -0.9756178855895996, -0.9801000356674194, -0.9755756855010986, -0.9856243133544922, -0.979116678237915, -0.9864267706871033, -0.9727951884269714, -0.9828903675079346, -0.9881740808486938, -0.9812456965446472, -0.982709527015686, -0.9910683631896973, -0.98741215467453, -0.9810203313827515, -0.9804816842079163, -0.9913521409034729, -0.9867364764213562, -0.9800518751144409, -0.9923698306083679, -0.9795125126838684, -0.9867401123046875, -0.9927214980125427, -0.9840009212493896, -0.9945212006568909, -0.9812420010566711, -0.9880178570747375, -0.9946258664131165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQPyanNY6qzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884f77e1-a205-46a0-afb3-d0847cd3da18"
      },
      "source": [
        "#oefen sample:\n",
        "sample = np.expand_dims(X_train[0], axis=0)\n",
        "preds = model.predict(sample, verbose=0)\n",
        "print(\"similarity with target: \", cosine_sim(preds, y_train[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "similarity with target:  [0.09675417]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wUGezstK3CA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}