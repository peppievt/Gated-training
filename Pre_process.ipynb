{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre_process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWKfFf/XoZfQorv2nFK9OA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peppievt/Gated-training/blob/main/Pre_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92GB1iYTqQle"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import specgram\n",
        "from matplotlib import style\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import keras\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "\n",
        "from keras.utils import np_utils, to_categorical\n",
        "import pickle\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.sparse as sparse\n",
        "import random\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tnrange, tqdm_notebook, tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U52JcP4HqUF4",
        "outputId": "b0b0bd16-ab57-4543-9665-9c3b858eac37"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVBF_D9WqYPa"
      },
      "source": [
        "#adres = r'C:\\Users\\pepij\\Documents\\Uni\\Datascience\\Thesis\\baldey_audio\\real_compound'\n",
        "#in colab:\n",
        "adres = r'/content/gdrive/My Drive/Colab Notebooks/data/baldey_audio/'\n",
        "opslag_adres = r'/content/gdrive/My Drive/Colab Notebooks/data/'\n",
        "learning_Rate = 0.002\n",
        "#style.use('dark_background')\n",
        "#options = ['real_derived', 'real_underived', 'real_compound', 'pseudo_derived', 'pseudo_underived', 'pseudo_compound']\n",
        "options = ['BALDEY_variants/real_derived']\n",
        "#options2 = ['BALDEY_variants/real_derived', 'BALDEY_variants/real_underived', 'BALDEY_variants/real_compound', 'BALDEY_variants/pseudo_derived', 'BALDEY_variants/pseudo_underived', 'BALDEY_variants/pseudo_compound']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1r1fIjAsR2A"
      },
      "source": [
        "def print_sound_wave(x):\n",
        "    for i in dir_list[0:x]:\n",
        "        fname = dir_list + '/' + i  \n",
        "        data, sampling_rate = librosa.load(fname)\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        librosa.display.waveplot(data, sr=sampling_rate)\n",
        "        \n",
        "def create_Y():\n",
        "    woordenlijst = []\n",
        "    for i in dir_list:\n",
        "        if i.endswith('.wav'):\n",
        "            woordenlijst.append(i[:-4])\n",
        "    return woordenlijst\n",
        "\n",
        "def create_RandomVector():\n",
        "    Vec = np.zeros(30)\n",
        "    randomlist = random.sample(range(0, 30), ones)\n",
        "    for i in randomlist:\n",
        "        Vec[i] = 1\n",
        "    return np.asarray(Vec)\n",
        "\n",
        "def create_Vectors():\n",
        "    Y = []\n",
        "    y = create_Y()\n",
        "    y2 = []\n",
        "    for i in range(len(y)):\n",
        "        x = create_RandomVector()\n",
        "        Y.append(x)\n",
        "    return Y\n",
        "\n",
        "def create_map_Vectors(woordenlijst):\n",
        "    omzet_df = pd.DataFrame(columns = ['woord', 'vector'])\n",
        "    woorden, vectoren = [],[]\n",
        "    for i in set(woordenlijst):\n",
        "        woorden.append(i)\n",
        "        vectoren.append(create_RandomVector())\n",
        "    omzet_df['woord'] = woorden\n",
        "    omzet_df['vector'] = vectoren\n",
        "    dictionary = dict(zip(omzet_df['woord'],omzet_df['vector']))\n",
        "    return dictionary\n",
        "\n",
        "def solve_table(df, di):\n",
        "    df['Y'] = df['name'].map(di)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTesdBQCqwhW"
      },
      "source": [
        "df_features = pd.DataFrame(columns=['feature'])\n",
        "counter =0\n",
        "\n",
        "def generate_features(options):\n",
        "    df_features = pd.DataFrame(columns=['feature'])\n",
        "    names = []\n",
        "    counter =0\n",
        "    c=0\n",
        "    for opt in range(len(options)):\n",
        "        dir_list = os.listdir(adres+options[opt])\n",
        "        print(\"\\noptie = \", options[opt])\n",
        "        print(\"lengte = \", len(dir_list))\n",
        "        for i in dir_list[0:10]:\n",
        "            if counter % 100 == 0:\n",
        "                print(\"counter: \", counter, i)\n",
        "            X, sample_rate = librosa.load((adres+options[opt]) + '/'+ i\n",
        "                                    #duration #check max of fragment. Niet A-priori doen, laten bepalen door het algoritme. achteraf bijstellen.\n",
        "                                    ,sr=None #native is more convenient.\n",
        "                                    ,offset=0\n",
        "                                    )\n",
        "            sample_rate = np.array(sample_rate)\n",
        "            samp = int(sample_rate/100)\n",
        "            specto = librosa.feature.melspectrogram(y=X, sr=sample_rate, hop_length=441)\n",
        "            #take the logarithm -> to decibel (MFSC):\n",
        "            specto = librosa.amplitude_to_db(specto, ref=np.max)\n",
        "            df_features.loc[counter] = [specto]\n",
        "            names.append(i.split('.')[0])\n",
        "            counter=counter+1 \n",
        "    return df_features, names\n",
        "\n",
        "def get_names(options):\n",
        "    names = []\n",
        "    counter =0\n",
        "    for opt in range(len(options)):\n",
        "        dir_list = os.listdir(adres+options[opt])\n",
        "        print(\"optie = \", options[opt])\n",
        "        for i in dir_list:\n",
        "            names.append(i.split('.')[0])\n",
        "            counter=counter+1 \n",
        "    return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U7yNdrLrlaT",
        "outputId": "e5fd1ff9-a1d1-4734-bafc-2f837d7cfd38"
      },
      "source": [
        "opties = options\n",
        "df_features, names = generate_features(opties)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "optie =  BALDEY_variants/real_derived\n",
            "lengte =  2280\n",
            "counter:  0 beteugelde.wav_110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbEudNAbYrQQ",
        "outputId": "05d1dea7-1ac6-4d2e-e20d-63ae4a6f47d7"
      },
      "source": [
        "print(df_features['feature'][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 77)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XteSmgM9UWp2"
      },
      "source": [
        "df_features.to_pickle(opslag_adres + 'fake_2_specto_baldey.pkl') \n",
        "df_name = pd.DataFrame(names)\n",
        "df_name.to_pickle(opslag_adres +'fake_2_specto_baldey_names.pkl')\n",
        "print(\"check dataset even lang als losse sets: \", len(df_features))\n",
        "print(\"lengte names\", len(df_name))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}